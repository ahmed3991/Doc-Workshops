{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/ultralytics/notebooks/blob/main/notebooks/how-to-train-ultralytics-yolo-on-brain-tumor-detection-dataset.ipynb","timestamp":1763860575608}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"t6MPjfT5NrKQ"},"source":["<div align=\"center\">\n","\n","  <a href=\"https://ultralytics.com/yolo\" target=\"_blank\">\n","    <img width=\"1024\", src=\"https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png\"></a>\n","\n","  [ä¸­æ–‡](https://docs.ultralytics.com/zh/) | [í•œêµ­ì–´](https://docs.ultralytics.com/ko/) | [æ—¥æœ¬èª](https://docs.ultralytics.com/ja/) | [Ğ ÑƒÑÑĞºĞ¸Ğ¹](https://docs.ultralytics.com/ru/) | [Deutsch](https://docs.ultralytics.com/de/) | [FranÃ§ais](https://docs.ultralytics.com/fr/) | [EspaÃ±ol](https://docs.ultralytics.com/es/) | [PortuguÃªs](https://docs.ultralytics.com/pt/) | [TÃ¼rkÃ§e](https://docs.ultralytics.com/tr/) | [Tiáº¿ng Viá»‡t](https://docs.ultralytics.com/vi/) | [Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©](https://docs.ultralytics.com/ar/)\n","\n","  <a href=\"https://github.com/ultralytics/ultralytics/actions/workflows/ci.yml\"><img src=\"https://github.com/ultralytics/ultralytics/actions/workflows/ci.yml/badge.svg\" alt=\"Ultralytics CI\"></a>\n","  <a href=\"https://colab.research.google.com/github/ultralytics/notebooks/blob/main/notebooks/how-to-train-ultralytics-yolo-on-brain-tumor-detection-dataset.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n","\n","  <a href=\"https://ultralytics.com/discord\"><img alt=\"Discord\" src=\"https://img.shields.io/discord/1089800235347353640?logo=discord&logoColor=white&label=Discord&color=blue\"></a>\n","  <a href=\"https://community.ultralytics.com\"><img alt=\"Ultralytics Forums\" src=\"https://img.shields.io/discourse/users?server=https%3A%2F%2Fcommunity.ultralytics.com&logo=discourse&label=Forums&color=blue\"></a>\n","  <a href=\"https://reddit.com/r/ultralytics\"><img alt=\"Ultralytics Reddit\" src=\"https://img.shields.io/reddit/subreddit-subscribers/ultralytics?style=flat&logo=reddit&logoColor=white&label=Reddit&color=blue\"></a>\n","  \n","  Welcome to the Brain-tumor detection using Ultralytics YOLO11 ğŸš€ notebook! <a href=\"https://github.com/ultralytics/ultralytics\">YOLO11</a> is the latest version of the YOLO (You Only Look Once) AI models developed by <a href=\"https://ultralytics.com\">Ultralytics</a>. We hope that the resources in this notebook will help you get the most out of YOLO11. Please browse the YOLO11 <a href=\"https://docs.ultralytics.com/\">Docs</a> for details, raise an issue on <a href=\"https://github.com/ultralytics/ultralytics\">GitHub</a> for support, and join our <a href=\"https://ultralytics.com/discord\">Discord</a> community for questions and discussions!</div>"]},{"cell_type":"markdown","source":["# Brain Tumor Detection using Ultralytics YOLO11\n","\n","This notebook serves as an initial step for training the YOLO11 model on the [brain-tumor](https://docs.ultralytics.com/datasets/detect/brain-tumor/) detection dataset."],"metadata":{"id":"7EM2nwU4jshF"}},{"cell_type":"markdown","source":["## Dataset Structure\n","\n","The brain tumor dataset is divided into two subsets:\n","\n","- **Training set**: Consisting of 893 images, each accompanied by corresponding annotations.\n","- **Testing set**: Comprising 223 images, with annotations paired for each one."],"metadata":{"id":"xypoYW_oYZAf"}},{"cell_type":"markdown","source":["## Applications\n","\n","The application of brain tumor detection using computer vision enables early diagnosis, treatment planning, and monitoring of tumor progression. By analyzing medical imaging data like MRI or CT scans, computer vision systems assist in accurately identifying brain tumors, aiding in timely medical intervention and personalized treatment strategies."],"metadata":{"id":"R4SICbq5Yalg"}},{"cell_type":"markdown","metadata":{"id":"7mGmQbAO5pQb"},"source":["## Setup\n","\n","pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/pyproject.toml) and check software and hardware.\n","\n","[![PyPI - Version](https://img.shields.io/pypi/v/ultralytics?logo=pypi&logoColor=white)](https://pypi.org/project/ultralytics/) [![Downloads](https://static.pepy.tech/badge/ultralytics)](https://clickpy.clickhouse.com/dashboard/ultralytics) [![PyPI - Python Version](https://img.shields.io/pypi/pyversions/ultralytics?logo=python&logoColor=gold)](https://pypi.org/project/ultralytics/)"]},{"cell_type":"code","metadata":{"id":"wbvMlHd_QwMG","colab":{"base_uri":"https://localhost:8080/"},"outputId":"14a55d0b-3fc6-40e8-b927-74d315a35bed","executionInfo":{"status":"ok","timestamp":1763889243733,"user_tz":-60,"elapsed":5131,"user":{"displayName":"ahmed ghenabzia","userId":"13665366370528167859"}}},"source":["!uv pip install ultralytics\n","import ultralytics\n","ultralytics.checks()"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.230 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n","Setup complete âœ… (2 CPUs, 12.7 GB RAM, 37.9/112.6 GB disk)\n"]}]},{"cell_type":"markdown","source":["## Dataset YAML File\n","\n","A YAML (Yet Another Markup Language) file defines the dataset configuration, including paths, classes, and other pertinent details. ğŸ˜€"],"metadata":{"id":"xE6ntKojSfSD"}},{"cell_type":"markdown","source":["```yaml\n","# Ultralytics YOLO ğŸš€, AGPL-3.0 license\n","# Brain-tumor dataset by Ultralytics\n","# Documentation: https://docs.ultralytics.com/datasets/detect/brain-tumor/\n","# Example usage: yolo train data=brain-tumor.yaml\n","# parent\n","# â”œâ”€â”€ ultralytics\n","# â””â”€â”€ datasets\n","#     â””â”€â”€ brain-tumor  â† downloads here (4.21 MB)\n","\n","# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]\n","path: brain-tumor # dataset root dir\n","train: images/train # train images (relative to 'path') 893 images\n","val: images/val # val images (relative to 'path') 223 images\n","\n","# Classes\n","names:\n","  0: negative\n","  1: positive\n","\n","# Download script/URL (optional)\n","download: https://github.com/ultralytics/assets/releases/download/v0.0.0/brain-tumor.zip\n","```"],"metadata":{"id":"h8go3HNgN0WU"}},{"cell_type":"markdown","source":["## Train\n","\n","Train YOLO11 on [Detect](https://docs.ultralytics.com/tasks/detect/), [Segment](https://docs.ultralytics.com/tasks/segment/), [Classify](https://docs.ultralytics.com/tasks/classify/) and [Pose](https://docs.ultralytics.com/tasks/pose/) datasets. See [YOLO11 Train Docs](https://docs.ultralytics.com/modes/train/) for more information."],"metadata":{"id":"fMV-sNfiSt_X"}},{"cell_type":"code","source":["from ultralytics import YOLO\n","\n","# Load a model\n","model = YOLO(\"yolo11n.pt\")  # load a pretrained model (recommended for training)\n","\n","# Train the model\n","results = model.train(data=\"brain-tumor.yaml\", epochs=10, imgsz=640)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QUgMYUvlNLvy","outputId":"c77cfda6-08fe-45f6-a6b6-58d144cec121","executionInfo":{"status":"ok","timestamp":1763889471778,"user_tz":-60,"elapsed":213290,"user":{"displayName":"ahmed ghenabzia","userId":"13665366370528167859"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 97.6MB/s 0.1s\n","Ultralytics 8.3.230 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=brain-tumor.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","WARNING âš ï¸ Dataset 'brain-tumor.yaml' images not found, missing path '/content/datasets/brain-tumor/images/val'\n","\u001b[KDownloading https://ultralytics.com/assets/brain-tumor.zip to '/content/datasets/brain-tumor.zip': 100% â”â”â”â”â”â”â”â”â”â”â”â” 4.2MB 97.1MB/s 0.0s\n","\u001b[KUnzipping /content/datasets/brain-tumor.zip to /content/datasets/brain-tumor...: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2225/2225 6.6Kfiles/s 0.3s\n","Dataset download success âœ… (0.7s), saved to \u001b[1m/content/datasets\u001b[0m\n","\n","\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 23.6MB/s 0.0s\n","Overriding model.yaml nc=80 with nc=2\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n"," 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n"," 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n"," 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n"," 23        [16, 19, 22]  1    431062  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n","YOLO11n summary: 181 layers, 2,590,230 parameters, 2,590,214 gradients, 6.4 GFLOPs\n","\n","Transferred 448/499 items from pretrained weights\n","Freezing layer 'model.23.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 185.3Â±115.5 MB/s, size: 3.6 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/brain-tumor/labels/train... 878 images, 15 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 893/893 2.7Kit/s 0.3s\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/brain-tumor/labels/train.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 181.6Â±98.9 MB/s, size: 3.9 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/brain-tumor/labels/val... 223 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 223/223 2.1Kit/s 0.1s\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/brain-tumor/labels/val.cache\n","Plotting labels to /content/runs/detect/train/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/content/runs/detect/train\u001b[0m\n","Starting training for 10 epochs...\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       1/10      2.21G      1.304      3.854      1.224         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 56/56 1.6it/s 34.7s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 1.1s/it 7.6s\n","                   all        223        241    0.00185      0.525     0.0292     0.0138\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       2/10      2.74G        1.2       2.74      1.132         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 56/56 4.0it/s 13.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 3.3it/s 2.2s\n","                   all        223        241      0.402      0.517      0.318      0.211\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       3/10      2.75G      1.157      2.289      1.114         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 56/56 3.9it/s 14.5s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 4.1it/s 1.7s\n","                   all        223        241      0.445      0.666      0.439        0.3\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       4/10      2.77G      1.144      1.964      1.106         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 56/56 4.2it/s 13.4s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 4.4it/s 1.6s\n","                   all        223        241      0.427      0.708      0.431      0.283\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       5/10      2.79G      1.084      1.735      1.084         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 56/56 4.1it/s 13.5s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 4.5it/s 1.5s\n","                   all        223        241      0.433      0.783      0.463      0.316\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       6/10       2.8G      1.075      1.575      1.067         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 56/56 4.1it/s 13.6s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 4.4it/s 1.6s\n","                   all        223        241      0.454       0.86      0.485       0.33\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       7/10      2.82G       1.01      1.456      1.034         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 56/56 4.0it/s 14.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 4.0it/s 1.7s\n","                   all        223        241      0.447      0.864      0.483      0.346\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       8/10      2.83G       0.96      1.401      1.034         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 56/56 4.2it/s 13.4s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 4.3it/s 1.6s\n","                   all        223        241      0.462      0.851      0.484      0.346\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       9/10      2.85G     0.9322      1.325      1.004         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 56/56 4.1it/s 13.6s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 4.7it/s 1.5s\n","                   all        223        241      0.465      0.864      0.481      0.345\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      10/10      2.86G     0.9066       1.27     0.9986         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 56/56 4.2it/s 13.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 4.7it/s 1.5s\n","                   all        223        241       0.47      0.861      0.477      0.344\n","\n","10 epochs completed in 0.051 hours.\n","Optimizer stripped from /content/runs/detect/train/weights/last.pt, 5.5MB\n","Optimizer stripped from /content/runs/detect/train/weights/best.pt, 5.5MB\n","\n","Validating /content/runs/detect/train/weights/best.pt...\n","Ultralytics 8.3.230 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n","YOLO11n summary (fused): 100 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.3it/s 3.0s\n","                   all        223        241      0.447      0.864      0.483      0.347\n","              negative        142        154      0.568      0.831      0.601       0.43\n","              positive         81         87      0.326      0.897      0.366      0.263\n","Speed: 0.2ms preprocess, 2.6ms inference, 0.0ms loss, 2.9ms postprocess per image\n","Results saved to \u001b[1m/content/runs/detect/train\u001b[0m\n"]}]},{"cell_type":"markdown","source":["![Brain tumor dataset sample image](https://github.com/ultralytics/docs/releases/download/0/brain-tumor-dataset-sample-image.avif)"],"metadata":{"id":"_Hapx6WkS--T"}},{"cell_type":"markdown","source":["## Predict\n","\n","YOLO11 may be used directly in the Command Line Interface (CLI) with a yolo command for a variety of tasks and modes and accepts additional arguments, i.e. imgsz=640. See a full list of available [yolo arguments](https://docs.ultralytics.com/usage/cfg/) and other details in the [YOLO11 Predict Docs](https://docs.ultralytics.com/modes/train/)."],"metadata":{"id":"mKAUvDAbTEjQ"}},{"cell_type":"code","source":["from ultralytics import YOLO\n","\n","# Load a model\n","modelp = YOLO(f\"{model.trainer.save_dir}/weights/best.pt\")  # load a fine-tuned model\n","\n","# Inference using the model (img/video/stream)\n","prediction_results = modelp.predict(\"https://ultralytics.com/assets/brain-tumor-sample.jpg\", save=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nzTbeqK_TB6t","outputId":"f2df2be1-25ec-49c8-b6df-4ce1a7bd0c8d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Downloading https://ultralytics.com/assets/brain-tumor-sample.jpg to 'brain-tumor-sample.jpg'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.49k/5.49k [00:00<00:00, 6.00MB/s]"]},{"output_type":"stream","name":"stdout","text":["image 1/1 /content/brain-tumor-sample.jpg: 640x640 1 positive, 16.4ms\n","Speed: 3.1ms preprocess, 16.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img align=\"left\" src=\"https://github.com/user-attachments/assets/f44df643-3ffc-4f3c-a08d-c213a1f24abb\" width=\"600\">"],"metadata":{"id":"lmNKY3rWWsvj"}},{"cell_type":"markdown","source":["## Export\n","\n","Export a YOLO11 model to any supported format below with the `format` argument, i.e. `format=onnx`. See [YOLO11 Export Docs](https://docs.ultralytics.com/modes/export/) for more information.\n","\n","- ğŸ’¡ ProTip: Export to [ONNX](https://docs.ultralytics.com/integrations/onnx/) or [OpenVINO](https://docs.ultralytics.com/integrations/openvino/) for up to 3x CPU speedup.  \n","- ğŸ’¡ ProTip: Export to [TensorRT](https://docs.ultralytics.com/integrations/tensorrt/) for up to 5x GPU speedup.\n","\n","| Format                                                                   | `format` Argument | Model                     | Metadata | Arguments                                                            |\n","|--------------------------------------------------------------------------|-------------------|---------------------------|----------|----------------------------------------------------------------------|\n","| [PyTorch](https://pytorch.org/)                                          | -                 | `yolo11n.pt`              | âœ…        | -                                                                    |\n","| [TorchScript](https://docs.ultralytics.com/integrations/torchscript)     | `torchscript`     | `yolo11n.torchscript`     | âœ…        | `imgsz`, `optimize`, `batch`                                         |\n","| [ONNX](https://docs.ultralytics.com/integrations/onnx)                   | `onnx`            | `yolo11n.onnx`            | âœ…        | `imgsz`, `half`, `dynamic`, `simplify`, `opset`, `batch`             |\n","| [OpenVINO](https://docs.ultralytics.com/integrations/openvino)           | `openvino`        | `yolo11n_openvino_model/` | âœ…        | `imgsz`, `half`, `dynamic`, `int8`, `batch`                          |\n","| [TensorRT](https://docs.ultralytics.com/integrations/tensorrt)           | `engine`          | `yolo11n.engine`          | âœ…        | `imgsz`, `half`, `dynamic`, `simplify`, `workspace`, `int8`, `batch` |\n","| [CoreML](https://docs.ultralytics.com/integrations/coreml)               | `coreml`          | `yolo11n.mlpackage`       | âœ…        | `imgsz`, `half`, `int8`, `nms`, `batch`                              |\n","| [TF SavedModel](https://docs.ultralytics.com/integrations/tf-savedmodel) | `saved_model`     | `yolo11n_saved_model/`    | âœ…        | `imgsz`, `keras`, `int8`, `batch`                                    |\n","| [TF GraphDef](https://docs.ultralytics.com/integrations/tf-graphdef)     | `pb`              | `yolo11n.pb`              | âŒ        | `imgsz`, `batch`                                                     |\n","| [TF Lite](https://docs.ultralytics.com/integrations/tflite)              | `tflite`          | `yolo11n.tflite`          | âœ…        | `imgsz`, `half`, `int8`, `batch`                                     |\n","| [TF Edge TPU](https://docs.ultralytics.com/integrations/edge-tpu)        | `edgetpu`         | `yolo11n_edgetpu.tflite`  | âœ…        | `imgsz`                                                              |\n","| [TF.js](https://docs.ultralytics.com/integrations/tfjs)                  | `tfjs`            | `yolo11n_web_model/`      | âœ…        | `imgsz`, `half`, `int8`, `batch`                                     |\n","| [PaddlePaddle](https://docs.ultralytics.com/integrations/paddlepaddle)   | `paddle`          | `yolo11n_paddle_model/`   | âœ…        | `imgsz`, `batch`                                                     |\n","| [MNN](https://docs.ultralytics.com/integrations/mnn)                     | `mnn`             | `yolo11n.mnn`             | âœ…        | `imgsz`, `batch`, `int8`, `half`                                     |\n","| [NCNN](https://docs.ultralytics.com/integrations/ncnn)                   | `ncnn`            | `yolo11n_ncnn_model/`     | âœ…        | `imgsz`, `half`, `batch`                                             |\n","| [IMX500](https://docs.ultralytics.com/integrations/sony-imx500)          | `imx`             | `yolo11n_imx_model/`      | âœ…        | `imgsz`, `int8`                                                      |\n","| [RKNN](https://docs.ultralytics.com/integrations/rockchip-rknn)          | `rknn`            | `yolo11n_rknn_model/`     | âœ…        | `imgsz`, `batch`, `name`                                             |"],"metadata":{"id":"vWBYYdXhTkN7"}},{"cell_type":"code","source":["from ultralytics import YOLO\n","\n","# Load a model\n","modele = YOLO(f\"{model.trainer.save_dir}/weights/best.pt\")  # load a fine-tuned model\n","\n","# Export the model\n","modele.export(format=\"onnx\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":298},"id":"S4nWG40CTlOD","outputId":"714e2750-9c39-40c7-f402-0492aaff3e5b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.57 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CPU (Intel Xeon 2.20GHz)\n","YOLO11n summary (fused): 238 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n","\n","\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/runs/detect/train/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 6, 8400) (5.2 MB)\n","\n","\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n","\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.46...\n","\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 1.5s, saved as '/content/runs/detect/train/weights/best.onnx' (10.1 MB)\n","\n","Export complete (2.2s)\n","Results saved to \u001b[1m/content/runs/detect/train/weights\u001b[0m\n","Predict:         yolo predict task=detect model=/content/runs/detect/train/weights/best.onnx imgsz=640  \n","Validate:        yolo val task=detect model=/content/runs/detect/train/weights/best.onnx imgsz=640 data=/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/datasets/brain-tumor.yaml  \n","Visualize:       https://netron.app\n"]},{"output_type":"execute_result","data":{"text/plain":["'/content/runs/detect/train/weights/best.onnx'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["## Citation\n","\n","```bibtex\n","@dataset{Jocher_Ultralytics_Datasets_2024,\n","    author = {Jocher, Glenn and Rizwan, Muhammad},\n","    license = {AGPL-3.0},\n","    month = {March},\n","    title = {Ultralytics Datasets:Brain-tumor Detection Dataset},\n","    url = {https://docs.ultralytics.com/datasets/detect/brain-tumor/},\n","    version = {1.0.0},\n","    year = {2024}\n","}\n"],"metadata":{"id":"vlHp09Nueb3d"}}]}